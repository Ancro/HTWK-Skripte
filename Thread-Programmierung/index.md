## Thread-Programmierung
### Gliederung
1. Grundbegriffe
	1. Threads
	2. Nicht-Determinismus
	3. Kritische Bereiche
	4. Sperren
2. Verifikation
	1. Zeitliche AblÃ¤ufe
	2. Serielle AblÃ¤ufe
	3. Faire Mischung
	4. Sicherheits- und Liveness-Eigenschaften
	5. Modellierung
3. Synchronisation
	1. Signale (Bsp. Erzeuger/Verbraucher)
	2. Semaphore
	3. Bedingte kritische Bereiche
	4. Wiederbehebbare Sperre
	5. Leser/Schreiber-Problem
4. FeinkÃ¶rnige NebenlÃ¤ufigkeit
	1. Methoden (Bsp. Mengen)
	2. GrobkÃ¶rnig
	3. FeinkÃ¶rnig
	4. Optimistisch
	5. Faul
	6. Mit atomaren Befehlen
5. Implementierung
	1. Atomare Befehle
	2. Konsenzzahlen
	3. Zwischenspeicher
	4. BÃ¤ckerei-Algorithmus
6. Transactional Memory
	1. Probleme mit Sperren
	2. Transaktionen
	3. STM: Transaktionsstatus, Transactional Thread, 2 Implementierungen

Literatur:
- Maurice Herlihy, Nir Shavit: The Art of Multiprocessor Programming. Morgan Kaufmann 2008.
- Kelvin Lin, Larry Snyder: Principles of Parallel Programming. Addison Wesley.
- Greg Andrews: Concurrent Programming. Addison Wesley 1991.
- Brian Goetz u.a.: Java Concurrency in Practice. Addison Wesley 2006.

## 1. Grundbegriffe
### 1.1. Threads
**Prozess (hier)** := sequentieller Rechenvorgang  
**Sequentiell (auch: seriell)Â **:= Alle Rechenschritte laufen nacheinander ab in einer vorgegebenen Reihenfolge.  
**Thread (deutsch: Faden)** := leichte Variante eines Prozesses

###### Allgemeine Tendenz:
1. Systemkern mÃ¶glichst schlank halten
2. Systemkern mÃ¶glichst selten betreten

###### Unterschied zu Prozess:
- kein eigener Speicherbereich
- Ã¼blicherweise nicht vom Systemkern verwaltet

###### â€Leichtprozessâ€œ (engl. light-weight prozess):
- vom Systemkern verwaltet
- Vorteile:
	- Wechsel zwischen Threads weniger aufwendig als Wechsel zwischen Prozessen
	- Threads benÃ¶tigen weniger Speicher
	- man kann viel mehr Threads (â‰ˆ10000) als Prozesse (â‰ˆ100) laufen lassen.
- Nachteile:
	- Der Anwendungsprogrammierer muss sich um die Verwaltung der Threads kÃ¼mmern 

Viele Programmiersprachen bieten heute Programmbibliotheken fÃ¼r Threads an (Beispiel: PThread in C). Wir verwenden in dieser Veranstaltung Java als Programmiersprache.

**Parallel** := mehrere Threads laufen gleichzeitig auf verschiedenen Rechnerkernen.  
**VerschrÃ¤nkt (engl. interleaved)** := die Threads laufen abwechselnd je ein StÃ¼ck weit  
**Nebeneinander laufend (auch: nebenlÃ¤ufig, engl. concurrent)** := mehrere Threads laufen parallel oder miteinander verschrÃ¤nkt.  
Auch Mischformen sind mÃ¶glich.

###### Unterschied:
- **Rechenzeit (engl. CPU time)** := Zeit, die der Prozessor mit Rechnen zubringt
- **Bearbeitungszeit (engl. wall clock time)** := umfasst auch Wartezeiten

##### Amdahlsches Gesetz (Gene Amdahl 1967):
> Wenn eine Aufgabe die Bearbeitungszeit a benÃ¶tigt, und der Anteil 0 â‰¤ p â‰¤ 1 davon parallelisiert ist, dann benÃ¶tigt sie die Bearbeitungszeit  
> `a * (1 - p + p/n)`.

Beispiel: `p = 9/10, n = 100`.
Beschleunigung (engl. speedup)  
= `a / (a * (1 - p + p/n))`  
= `1 / (1 - 9/10 + 9/1000)`  
â‰ˆ 9,17

Sogar `lim[n â†’ âˆ] 1 / (1 - p + p/n)` = `1 / (1 - p)` = 10.

*Fazit*: Der nicht-parallelisierbare Anteil dominiert die Bearbeitungszeit.

### 1.2. Nicht-Determinismus
**Nicht-Determinismus** := das Verhalten eines Systems hat Freiheitsgrade
Nicht-Determinismus hat zwei Anwendungen:
1. MÃ¶glichkeiten des Verhaltens der Systemumgebung zusammenfassen (engl. donâ€™t know nondeterminism).
2. Spielraum fÃ¼r Implementierungen (engl. donâ€™t care nondeterminism).

Hier: System von Threads.  
Man muss davon ausgehen, dass die Rechenschritte des Threads beliebig miteinander verschrÃ¤nkt sind. Die Reihenfolge der Schritte eines Threads ist durch sein Programm vorgegeben (â€Programm-Reihenfolgeâ€œ).

Der *Zeitplaner* (engl. scheduler) legt zur Laufzeit fest, in welcher Reihenfolge die Schritte zweier Threads zueinander ablaufen. Man mÃ¶chte den Zeitplaner in seiner Entscheidungsfreiheit nicht unnÃ¶tig einschrÃ¤nken, sondern einen mÃ¶glichst groÃŸen Spielraum lassen. Man verlangt deshalb, dass das System von Threads korrekt arbeitet unabhÃ¤ngig davon, wie der Zeitplaner die VerschrÃ¤nkung bildet. Donâ€™t know nondeterminism aus Sicht des Anwendungsprogrammierers, donâ€™t care nondeterminism aus Sicht des Zeitplaners.

Beispiel:  
Thread 1 fÃ¼hrt aus â‘  â‘¡ â‘¢.  
Thread 2 fÃ¼hrt aus â“ â“‘ â“’.  
Beispiele fÃ¼r mÃ¶gliche AblÃ¤ufe:

- â‘  â“ â‘¡ â“‘ â‘¢ â“’ (blau)
- â“ â“‘ â“’ â‘  â‘¡ â‘¢ (rot)
- â“ â‘  â“‘ â‘¡ â“’ â‘¢ (schlamm)
- â€¦

![Race Condition](Race%20Condition.jpg "Race Condition")

Da bei jedem Test der Zeitplaner eine andere AusfÃ¼hrungsreihenfolge (â€UmstÃ¤nde des Wettrennensâ€œ, engl. race condition) wÃ¤hlen kann, ist der Test praktisch nicht reproduzierbar. Wegen der groÃŸen Anzahl mÃ¶glicher AblÃ¤ufe ist ein systematisches Testen aussichtslos (â€Zustandsexplosionâ€œ).

Der Entickler muss deswegen die Korrektheit seines Programmes mathematisch beweisen (â€verifizierenâ€œ). Um FlÃ¼chtigkeitsfehler und Ã¼bersehene SpezialfÃ¤lle auszuschlieÃŸen, fÃ¼hrt man die Beweise mit Assistenzwerkzeugen durch und lÃ¤sst die Beweise maschinell Ã¼berprÃ¼fen: â€Formale Verfifikationâ€œ.

Threads sind asynchron, das heiÃŸt, sie laufen mit verschiedenen Geschwindigkeiten. Es treten Wartezeiten auf, deren Zeitpunkt und Dauer nicht vorhersehbar ist, z.B. eine neue Speicherseite muss geladen werden (â€page faultâ€œ), oder ein Zugriff auf den Zwischenspeicher (cache) scheitert.

### 1.3. Kritische Bereiche
Beispiel: ZÃ¤hler mit Threads *z* ist eine *gemeinsame Variable* (auch: gemeinsamer Speicher, engl. shared memory,  gemeinsames Objekt)

z++ wird vom Compiler sinngemÃ¤ÃŸ so Ã¼bersetzt:

1. `int temp := z;`
2. `temp := temp + 1;`
3. `z := temp;`

Beispielablauf fÃ¼r 3 verschiedene Threads:  
Sei z = 0 zu Anfang. Jeder Thread hat seine Version von temp. Der Wert von *z* sollte am Ende 3 sein.

```
	      p1      |       p2      |       p3      | z
	--------------|---------------|---------------|---
	Zeile | temp1 | Zeile | temp2 | Zeile | temp3 | 0
	------|-------|-------|-------|-------|-------|---
	   1  |   0   |       |       |       |       |
	      |       |   1   |   0   |       |       |
	      |       |   2   |   1   |       |       |
	      |       |   3   |       |       |       | 1
	      |       |       |       |   1   |   1   |
	      |       |       |       |   2   |   2   |
	      |       |       |       |   3   |       | 2
	   2  |   1   |       |       |       |       |
	   3  |       |       |       |       |       | 1
```

Threads p1, p2 p3 kommen sich gegenseitig in die Quere: *Einmischung* (eng. interference). Einmischung kann es nur Ã¼ber gemeinsame Variablen geben. Eine Methode, Einmischung zu verhindern, ist die Verwendung von kritischen Bereichen.

Kritischer Bereich (auch: kritischer Abschnitt, engl. critical region, critical section) := Programmfragment, in dem sich zu jedem Zeitpunkt hÃ¶chstens ein Thread befindet.

Ein kritischer Bereich ist ein â€exklusivesâ€œ Betriebsmittel. Wenn sich ein Thread im kritischen Bereich befindet, dann werden alle anderen Threads davon abgehalten, den kritischen Bereich zu betreten (*â€gegenseitiger Ausschlussâ€œ*, engl. mutual exclusion).

Beispiele fÃ¼r exklusive Betriebsmittel:
- Rechnerkern
- Schreibzugriff auf Speicherblock
- Schreibzugriff auf Bus
- Drucker

Schreibweise: `gemeinsam int z := 0;`  
(deklariert eine gemeinsame Variable z)

	kritisch z {
		z++
	}

Nur innerhalb des kritischen Bereichs darf auf die gemeinsame Variable zugegriffen werden. Wenn kritische Bereiche als Sprachkonstrukt gegeben sind, kann der Compiler die korrekte Verwendung kritischer Bereiche Ã¼berprÃ¼fen.

### 1.4. Sperren
Sperre (engl. lock) := Datenstruktur mit zwei mÃ¶glichen ZustÃ¤nden (â€belegtâ€œ und â€freiâ€œ) und zwei Zugriffsoperationen (â€belegenâ€œ und â€freigebenâ€œ).

Sperre `l` ist frei, wenn `l.frei` = `true`.

	belegen(l):
		Warten solange l.frei = false.
		Setze l.frei = false.
	
	freigeben(l):
		Setze l.frei = true.

Sperren kÃ¶nnen verwendet werden, um kritische Bereiche zu implementieren.

Beispiel: Sperre `l` beacht die gemeinsame Variable *z*.  
Programm:
- Sperre `l` anlegen mit `l.frei = false`.
- Threads anlegen. Setze gemeinsame Variable z = 0.
- `freigeben(l)`.

Thread: 
- â“ª `belegen(l);`
- â‘  â‘¡ â‘¢ `z++;`
- â‘£ `freigeben(l);`

Beispielablauf fÃ¼r 2 Threads nach `freigeben(l)` des Hauptprogramms:

```
	      p1      |       p2      | z | l.frei | Bemerkung
	--------------|---------------|---|--------|----------
	Zeile | temp1 | Zeile | temp2 | 0 |  true  |
	------|-------|-------|-------|   |        |
	   0  |       |       |       |   |  false |
	      |       |   0   |       |   |        | p2 wartet in Z. 0
	   1  |   0   |   0   |       |   |        |
	   2  |   1   |   0   |       |   |        | 
	   3  |       |   0   |       | 1 |        |
	   4  |       |   0   |       |   |  true  |
	      |       |   0   |       |   |  false | Ende der Wartezeit
	      |       |   1   |   1   |   |        |
	      |       |   2   |   2   |   |        |
	      |       |   3   |       | 2 |        |
	      |       |   4   |       |   |  true  |
```

Sprechweise:
- â€Thread `p` *bewirbt sich* fÃ¼r die Sperre `l`â€œ bedeutet: `p` ruft `belegen(l)` auf
- â€`p` *erwirbt* `l`â€œ bedeutet: `p` betritt den kritischen Bereich; p beendet den Aufruf `belegen(l)`.
- â€`p` *besitzt* `l`â€œ bedeutet: `p` ist im kritischen Bereich
- Streit um die Sperre (engl. lock contention)

## 2. Verifikation
### 2.1. Zeitliche AblÃ¤ufe
Vorgegeben: Menge A von Aktionen

**Ereignis (hier)** := Paar bestehend aus Aktion und Zeitpunkt

Zu einem Ereignis e soll `aktion(e)` die Aktion ausdrÃ¼cken und `zeit(e)` den Zeitpunkt, an dem die Aktion stattfindet.

Idealisierende Annahmen:
1. Alles findet praktisch am selben Ort statt (sonst: verteilte Systems)
	â†’ Keine Probleme mit der Lichtgeschwindigkeit
	Zeit (hier) := Newtonsche Zeit
	Zeitpunkte := reelle Zahlen
	Newtonsche Zeit verlÃ¤uft:
	- absolut, das heiÃŸt unabhÃ¤ngig vom Beobachter (sonst: spezielle RelativitÃ¤tstheorie)
	- stetif, das heiÃŸt ohne SprÃ¼nge (sonst: Quantenmechanik)
	- unbeeinflusst von der Umgebung (z.B. Temperatur, sonst: allgemeine RelativitÃ¤tstheorie)
2. Ein Ereignis hat die Dauer Null.
	Einen Zeitraum kann man darstellen durch die Ereignisse â€Beginn des Zeitraumesâ€œ und â€Ende des Zeitraumesâ€œ.
3. Gleichzeitige Ereignisse sind gleich:
	`zeit(eâ‚) = zeit(eâ‚‚)` â‡’ `eâ‚ = eâ‚‚`

**Diskreter zeitlicher Ablauf (auch: Geschichte)** := Menge E von Ereignissen sodass

1. die Menge der Zeitpunkte von E keinen HÃ¤ufungspunkt und
2. die Menge der Zeitpunkte von E ein kleinstes Element hat.

Sonst: kontinuierliche VorgÃ¤nge (Reaktive Systeme).

Inkrement sind hier nicht die Zeitpunkte selber, sondern nur deren Lage zueinander, das heiÃŸt die Reihenfolge der Aktionen. Sonst: Echtzeitsysteme.

Relation â€â†’â€œ â€kommt vorâ€œ zwischen Ereignissen ist definiert als:

	eâ‚ â†’ eâ‚‚ âŸº zeit(eâ‚) < zeit(eâ‚‚)
(Leslie Lamport 1978)

Es gilt: â†’ ist irreflexiv, transitiv, total, fundiert (also eine Wohlordnung).

##### Definition
Eine Relation R â‰¤ E â¨‰ E auf der Menge E heiÃŸt

- *irreflexiv,* falls fÃ¼r alle e âˆˆ E gilt, (e, e) âˆ‰ R.
- *transitiv,* falls fÃ¼r alle eâ‚, eâ‚‚, eâ‚ƒ âˆˆ E gilt:
	Falls (eâ‚, eâ‚‚) âˆˆ R und (eâ‚‚, eâ‚ƒ) âˆˆ R, dann (eâ‚, eâ‚ƒ) âˆˆ R.
- *total,* fÃ¼r alle eâ‚, eâ‚‚ âˆˆ E gilt:
	Falls eâ‚ â‰  eâ‚‚, dann (eâ‚, eâ‚‚) âˆˆ R oder (eâ‚‚, eâ‚) âˆˆ R.
- *fundiert,* falls es keine unendliche Folge (eáµ¢)\_{i âˆˆ N} gibt mit eáµ¢ âˆˆ E fÃ¼r alle i âˆˆ N  
	i â†¦ eáµ¢  
	und (eáµ¢, eáµ¢â‚Šâ‚) âˆˆ R fÃ¼r alle i âˆˆ N.

###### Einschub:
R ist *azyklisch,* falls es keine endliche Folge (eâ‚, â€¦ eáµ¢) gibt mit (eâ‚, eâ‚‚) âˆˆ R, (eâ‚‚, eâ‚ƒ) âˆˆ R, â€¦, (eáµ¢â‚‹â‚, eáµ¢) âˆˆ R, (eáµ¢, eâ‚) âˆˆ R.

Es gilt: Falls R irreflexiv und transitiv ist, dann ist R auch azyklisch. FÃ¼r eine nicht leere Geschichte E sei *min E* definiert als das kleinste Element von E bezÃ¼glich â†’, das heiÃŸt dasjenige e âˆˆ E, fÃ¼r das gilt: âˆ€ f âˆˆ E \\{e}: e â†’ f  
(Das ist eine implizite Definition, also schlecht. [Anm. d. schreib. Stud.])

**Implizite Definition** := Definition durch eine charakteristische Eigenschaft.

**Wohldefiniertheit der impliziten Definition** := Es gibt genau ein Objekt, das die charakteristische Eigenschaft erfÃ¼llt.

Wohldefiniertheit von *min E* gilt, weil â†’ total und E (mindestens) ein kleinstes Element hat.

Das i-te Ereignis aus E (in Symbolen Eâ±) ist dann fÃ¼r i âˆˆ N, i â‰¤ |E| rekursiv definiert durch

	Eâ± = { min E, falls i = 1,
	     { (E\{min E}â±â»Â¹, sonst

Auch hier ist die Wohldefiniertheit zu zeigen.

Projektion auf eine Menge B von Aktionen (â€Sichtâ€œ):

	(Ï€_B)(E) := {e âˆˆ E | aktion(e) âˆˆ B}

Zustand zum Zeitpunkt t âˆˆ R:

	(z_t)(E) := {e âˆˆ E | zeit(e) < t}.

â€â†’â€œ fÃ¼r ZeitrÃ¤ume:

![](Zeitraeume.jpg)

A â†’ B: âŸº Ende des Zeitraums A kommt vor Beginn des Zeitraums B  
Es gilt: â†’ fÃ¼r ZeitrÃ¤ume ist **nicht** total.  
Wenn sich A und B Ã¼berlappen, gilt weder A â†’ B noch B â†’ A.

**Prozessalphabet âº(p)** := Menge der Aktionen, die der Thread p â€siehtâ€œ

Gemeinsame Aktionen von pâ‚ und pâ‚‚: âº(pâ‚)âˆ©âº(pâ‚‚)

**Einigkeit (engl. match)** := Ereignisse mit gemeinsamen Aktionen finden gemeinsam statt:

1. Ï€\_{âº(pâ‚) âˆ© âº(pâ‚‚)}(Eâ‚ âˆª Eâ‚‚) = Eâ‚ âˆ© Eâ‚‚
	Gleichwertig zu 1. sind:
2. Ï€\_{âº(pâ‚) âˆ© âº(pâ‚‚)}(Eâ‚ âŠ— Eâ‚‚) = Ã˜
3. Ï€\_{âº(pâ‚)}(Eâ‚‚) = Ï€\_{âº(pâ‚‚)}(Eâ‚)

![](Venn-Diagramm.jpg)

Eáµ¢ Ereignisse von Thread i  
Es gilt: âˆ€ e âˆˆ Eáµ¢: aktion(e) âˆˆ âº(páµ¢)  
Faire Mischung: Eâ‚âˆªEâ‚‚  
Es gilt: Ï€\_{âº(páµ¢)}(Eâ‚âˆªEâ‚‚) = Eáµ¢, fÃ¼r i âˆˆ {1, 2}, falls sich pâ‚ und pâ‚‚ einig sind.

### 2.2. Serielle AblÃ¤ufe
Wenn man nicht an den Zeitpunkten der Ereignisse interessiert ist, sondern nur an ihrer Lage zueinander, kann man statt einer Ereignismenge auch eine Aktionenfolge als Beschreibungsmittel fÃ¼r einen Ablauf nehmen.

Beispiele: Sei A = {a, b}.  
Endliche Folge (a, b, a) kann auch dargestellt werden als Funktion  
f: {1, 2, 3} â†’ A mit

	f(x) = { a, falls x = 1 oder x = 3,
	       { b, sonst.

Wertetabelle von f:

```
	  x  | 1 2 3
	-----|-------
	f(x) | a b a
```
Unendliche Folge (a, b, b, a, b, b, â€¦) als Funktion f: N â†’ A mit

	f(x) = { a, falls x mod 3 = 1
	       { b, sonst.

(Miteinander identifiziert:)  
Aáµ k-Tupel von Elementen aus A  
{i âˆˆ N | i â‰¤ k} â†’ A Folgen der LÃ¤nge k

Um endliche und unendliche AblÃ¤ufe einheitlich zu modellieren, bildet man die Positionenmenge

	N_âˆ := Nâ‚€ âˆª {âˆ}.

Vergleich â‰¤ auf N\_{âˆ} sei definiert durch

	m â‰¤ n âŸº (n = âˆ) âˆ¨ m, n âˆˆ Nâ‚€ âˆ§ m â‰¤ n

Vergleich m â‰¤ n fÃ¼r m, n âˆˆ Nâ‚€ liefert dasselbe bei â‰¤ auf N\_{âˆ} wie bei â‰¤ auf Nâ‚€.  
Man sagt auch: â‰¤ auf N\_{âˆ} ist eine *Fortsetzung* von â‰¤ auf Nâ‚€.

\< auf N\_{âˆ} sei definiert durch m \< n âŸº m â‰¤ n âˆ§ m â‰  n.

Es gilt: \< auf N\_{âˆ} ist eine Fortsetzung von \< auf Nâ‚€ und eine Wohlordnung.  
Bemerkung: â‰¤ lÃ¤sst sich nicht weiter fortsetzen: â€Ordinalzahlenâ€œ.

Sei A eine Aktionenmenge.  
Dann sei A\* := âˆª\_{k âˆˆ Nâ‚€} Aáµ  
A^{âˆ} := A\*[^1] âˆª (N â†’ A)[^2]  
Es gilt: A^{âˆ} = âˆª\_{k âˆˆ Nâ‚€} ({i âˆˆ N | i â‰¤ k} â†’ A)  
Die LÃ¤nge \#\_{x} einer Aktionenfolge x ist definiert durch

	#_{x} = { âˆ, falls x âˆˆ (N â†’ A)
	        { k, falls x âˆˆ Aáµ

Es gilt \#\_{x} âˆˆ N\_{âˆ}.  
â‰¤\_{pre} â‰¤ A^{âˆ} â¨‰ A^{âˆ} sei definiert durch

	x â‰¤_{pre} y âŸº #_{x} â‰¤ #_{y} âˆ§ âˆ€ 1 â‰¤ i â‰¤ #_x: x(i) = y(i)

Beispiel:  
x = (a, b, a, a)  
y = (a, b, a, a, b, a, â€¦)

> â€x ist ein AnfangsstÃ¼ck (auch: PÃ¤fix, engl. prefix) von y.â€œ

Es gilt â‰¤\_{pre} ist eine Ordnungsrelation (das heiÃŸt â‰¤\_{pre} ist reflexiv, transitiv und antisymmetrisch).

\<\_{pre} ist definiert durch  
x \<\_{pre} y âŸº x â‰¤\_{pre} y âˆ§ x â‰  y

â€strikter Anteil von â‰¤\_{pre}â€œ

Es gilt: \<\_{pre} ist eine Striktordnung (das heiÃŸt irreflexiv und transitiv).

###### Operationen auf Aktionenfolgen:
rest: A^{âˆ}\\{Îµ[^3]} â†’ A^{âˆ}  
ist definiert durch  
rest(x)(i) = x(i + 1)

Es gilt: \#\_{rest(x)} = âˆ, falls \#\_{x} = âˆ und \#\_{rest(x)} = \#\_{x} = 1, sonst.

Konkatenation (= Hintereinanderstellen von Aktionenfolgen) ist definiert durch

	(x * y)(i) = { x(i), falls i â‰  #_{x},
	             { y(i - #_{x}), sonst.
	                    â†‘ Dieser Fall tritt nicht bei #_{x} = âˆ auf.

Es gilt: x \* y = x, falls  \#\_{x} = âˆ.

Projektion Ï€\_{B}: A^{âˆ} â†’ A^{âˆ} auf Aktionenmenge B ist rekursiv definiert durch:

	           { Îµ, falls x = Îµ,
	Ï€_{B}(x) = { x(1) * Ï€_{B}(rest(x)), falls 0 < #_x < âˆ & x(1) âˆˆ B
	           { Ï€_{B}(rest(x)), falls 0 < #_x < âˆ und x(1) âˆ‰ B
	           { sup {Ï€_{B}(y) | y <_{pre} x}

Beispiel:  
x = (a, b, c, a, b, c, â€¦)  
B = {a, b}  
Behauptung: Ï€\_{B} = (a, b, a, b, â€¦)  
Beweis: Es gilt \#\_{x} = âˆ  
Damit Ï€\_{B}(x) = sup {Ï€\_{B}(y) | y \<\_{pre} x}.  
yâ‚€ := Îµ[^4]  
yâ‚ := (a)[^5]  
yâ‚‚ := (a, b)[^6]  
yâ‚ƒ := (a, b, c)[^7]  
yâ‚„ := (a, b, c, a)[^8]  
â€¦

Die Anzahl \#\_{B}(x) der Vorkommen von Aktionen aus der Menge B in x âˆˆ A^{âˆ} ist definiert durch

	#_{B}(x) = #_{Ï€_{B}(x)}

Seien B âŠ† A, i âˆˆ N, x âˆˆ A^{âˆ}. Dann ist Bâ±\_{x} definiert duch

	Bâ±_{x} = #_{B} + 1, falls y * (a) â‰¤_{pre} x und a âˆˆ B und #_{B}(y) = i - 1.

Bâ±\_{x} liefert die Stelle des i-ten Vorkommens von einer Aktion aus B in x.

Wohldefiniertheit ist hier zu zeigen.  
Unendliche Wiederholung:  
FÃ¼r x âˆˆ Aáµ ist x^{âˆ} definiert durch

	x^{âˆ}(i) = x * ((i - 1) mod k + 1)

`(i - 1) mod k + 1` ist wie `i mod k`, auÃŸer wenn i ein Vielfaches von k ist: `(i - 1) mod k + 1` liefert dann k statt 0.

y ist ein Zustand der Aktionenfolge x (y ist Vergangenheit von x), wenn y â‰¤\_{pre} x und \#\_{y} âˆˆ Nâ‚€.

### 2.3. Faire Mischung
x âˆˆ (A âˆª B)^{âˆ} heiÃŸt eine *faire* Mischung (engl. fair merge) von y âˆˆ A^{âˆ} und z âˆˆ B^{âˆ}, wenn gilt

	Ï€_{A}(x) = y und Ï€_{B}(x) = z.

Bemerkung: â€fairâ€œ weil weder y noch z zu kurz kommen.  
Bemerkung: Statt â€faire Mischungâ€œ sagt man auch â€VerschrÃ¤nkungâ€œ oder â€shuffleâ€œ (bei Zeichenreihen).

Beispiel:  
Sei y = (0, 1)^{âˆ} = (0, 1, 0, 1, â€¦)  
und z = (2, 3)^{âˆ} = (2, 3, 2, 3, â€¦)  
mit A = {0, 1} und B = {2, 3}

Dann ist

	xâ‚ := (0, 2, 1, 3, 0, 2, 1, 3, â€¦) eine faire Mischung.
	      (0,    1,    0,    1,    â€¦) = y = Ï€_{A}(x)
	      (   2,    3,    2,    3, â€¦) = z = Ï€_{B}(x)

Spezialfall xâ‚ heiÃŸt auch â€perfect shuffleâ€œ.  
Aber auch

	xâ‚‚ := (2, 0, 1, 3, 2, 0, 1, 3, â€¦) ist eine faire Mischung.
	      (   0, 1,       0, 1,    â€¦)
	      (2,       3, 2,       3, â€¦)

x muss nicht periodisch sein oder y und z mit gleicher Geschwindigkeit behandeln.

### 2.4 Sicherheits- und Liveness-Eigenschaften
**Spezifikation** := Beschreibung der gewÃ¼nschten Eigenschaften des Systems aus Anwendersicht
**Verifikation** := Nachweis, dass das System seine Spezifikation erfÃ¼llt

Spezifikation eines sequentiellen Programms f: z â†’ z, wobei z die Menge aller ProgrammzustÃ¤nde sei:

	pre_f(z) â‡’ post_f(f(z))
	z := alter Zustand
	f(z) := neuer Zustand
	pre_f: Z â†’ B: Vorbedingung
	post_f: Z â†’ B: Nachbedingung

![](Prozeduraufruf.jpeg)

Problem bei Nebeneinander-Ablauf:

	               â†™ Wie verhÃ¤lt sich das System hier?
	â€“â€“â€“â€“â€“â€“|â€“â€“â€“â€“â€“â€“â€“â€“-|â€“â€“â€“â€“â€“â€“
	       --- f |--|
	       â€“â€“â€“â€“â€“â€“|â€“â€“â€“â€“â€“â€“â€“â€“-|â€“â€“â€“â€“â€“â€“
	              --- g ---

Prozedur-AusfÃ¼hrungen kÃ¶nnen sich Ã¼berlappen! Die AusfÃ¼hrung von f und die AusfÃ¼hrung von g kÃ¶nnen sich Ã¼ber gemeinsame Objekte gegenseitig beeinflussen!

Fazit: Das Verhalten einer Prozedur f ist durch pre\_{f} und post\_{f} nicht mehr genau genug beschreibbar.

	    Aktionen
	 â†™   â†“   â†“   â†˜
	â€“|â€“â€“â€“|â€“â€“â€“|â€“â€“â€“|â€“
	â†‘  â†‘   â†‘   â†‘  â†‘
	ZusicherungenÃ¼ber die ZustÃ¤nde

VereinfachungsmÃ¶glichkeiten:

- Aktionen, die keine gemeinsamen Objekte betreffen, kÃ¶nnen zusammengefasst werden zu einer Aktion
- Kritische Bereiche kÃ¶nnen zusammengefasst werden zu einer Aktion

**Sicherheitseigenschaft (auch Konsistenz, Invariante, engl. safety property)** := Eigenschaft, die fÃ¼r jeden Zustand gelten soll, und die sich nur auf vergangene ZustÃ¤nde bezieht.

**Liveness-Eigenschaft (auch: Fortschritt, engl. liveness property)** := alle Ã¼brigen Eigenschaften von AblÃ¤ufen

Grund fÃ¼r die Unterscheidung:

1. Sicherheitseigenschaften sind einfach zu beweisen.
2. Die meisten Eigenschaften sind Sicherheitseigenschaften.

Intuitiv:  
Eine Sicherheitseigenschaft garantiert, dass nichts unerwÃ¼nschtes geschieht (â€Verbotâ€œ). Eine Liveness-Eigenschaft garantiert, dass schlieÃŸlich etwas ErwÃ¼nschtes geschieht (â€Versprechenâ€œ). Ein Thread, der nur wartet, erfÃ¼llt alle Sicherheitseigenschaften. â€Wer schlÃ¤ft, sÃ¼ndigt nicht.â€œ

Bemerkung:  
Zu sequentiellen Programmen ist partielle Korrektheit eine Sicherheitseigenschaft und Termination eine Liveness-Eigenschaft.

Beweismethode fÃ¼r eine Sicherheitseigenschaft â€FÃ¼r jeden Zustand gilt Sâ€œ.

1. S gilt fÃ¼r den Startzustand.
2. S bleibt bei jedem ZustandsÃ¼bergang erhalten, das heiÃŸt, wenn S im alten Zustand gilt, dann auch im neuen Zustand.

Variante:

1. S gilt nach Initialisierung.
2. S bleibt auÃŸerhalb von kritischen Bereichen erhalten.
3. Wenn S beim Betreten eines kritischen Bereiches gilt, dann auch beim Verlassen.

Sperren sollen folgende Eigenschaften erfÃ¼llen:

1. **Gegenseitiger Ausschluss:**  Die kritischen Bereiche zweier Threads Ã¼berlagern sich nicht.  
	Sicherheitseigenschaft: â€In jedem Zustand ist verboten, dass zwei Threads im kritischen Bereich sind.â€œ
2. **Verklemmungsfreiheit:** Wenn ein Thread die Sperre erwerben mÃ¶chte, dann gibt es einen Thread, der die Sperre bekommt.  
	Liveness-Eigenschaft: â€Wenn die Sperre zugeteilt werden soll, wird sie schlieÃŸlich zugeteilt.â€œ
3. **Fairness (auch: kein Verhungern):**  
	Jeder Thread, der eine Sperre erwerben mÃ¶chte, bekommt sie schlieÃŸlich auch. Liveness-Eigenschaft.

Es gilt: Aus Fairness folgt Verklemmungsfreiheit. Bedingungen fÃ¼r Prozeduraufrufe im Zusammenhang mit nebeneinander laufenden Threads:

1. **Bounden wait-free:**  
	Jeder Prozeduraufruf terminiert nach einer beschrÃ¤nkten Anzahl von Schritten.
2. **Wait-free:**  
	Jeder Prozessaufruf terminiert, das heiÃŸt er bleibt nicht in einer Warteschleife hÃ¤ngen.
3. **Lock-free:**  
	Unendlich viele Aufrufe terminieren.

### 2.5 Modellierung:
Ausdrucksformen fÃ¼r Sicherheits- und Liveness-Eigenschaften:

- Formale Sprachen, insbesondere regulÃ¤re AusdrÃ¼cke
- Prozessalgebra
- Temporale Logik: linear oder verzweigend
- PrÃ¤dikatenlogik mit AblÃ¤ufen als Objekten

**Beispiel:** Modellierung von Sperren.  
Aktionen:

- antáµ¢: Thread i beantragt die Sperre
- beláµ¢: Thread i belegt die Sperre
- fráµ¢: Thread i gibt die Sperre wieder frei (verlÃ¤sst den kritischen Bereich)

![](Modellierung%20von%20Sperren.jpeg)

	Bel := {beláµ¢ | i âˆˆ I} (I ist die Menge der Threads)
Die Sperre wird belegt.

	Fr := {fráµ¢ | i âˆˆ I}
Die Sperre wird freigegeben.

Gegenseitiger Auschluss:

1. Mit regulÃ¤ren AusdrÃ¼cken  
	FÃ¼r jeden Ablauf x gilt: FÃ¼r jedes endliche AnfangsstÃ¼ck y von x gilt: Die Projektion von y auf die Aktionsmenge Bel âˆª Fr ist in der Sprache (Bel Fr)\* (Bel + Îµ) = PRE[^9]((Bel Fr)\*)
		Sei Ant := {antáµ¢ | i âˆˆ I} und A := Ant âˆª Bel âˆª Fr.
	Dann kann man gegenseitigen Ausschluss als Formel angeben:  
	âˆ€ x âˆˆ A^{âˆ}: âˆ€ y â‰¤\_{pre} x:  
	\#\_{y} \< âˆ â‡’ Ï€\_{Bel âˆª Fr(y)} âˆˆ PRE((Bel Fr)\*)  
	Ausgeschlossen ist z.B. der Ablauf â€belâ‚ belâ‚ frâ‚‚â€œ  
	PrÃ¤fix-Abschluss ist definiert durch  
	PRE(x) = {y âˆˆ A\* | y â‰¤\_{pre} X}

Formel fÃ¼r gegenseitigen Ausschluss kompakter:  
Ï€\_{Bel âˆª Fr}(PRE(x)) âŠ† PRE((Bel Fr)\*)  
Zugelassen ist zum Beispiel der Ablauf belâ‚ frâ‚‚ antâ‚.  
Ausgeschlossen ist zum Beispiel belâ‚ belâ‚ frâ‚‚.  
Falls y â‰¤\_{pre} x und x âˆˆ X, dann y âˆˆ PRE(X).  
x âŠ† A\* ist *abgeschlossen unter PrÃ¤fix*, falls PRE(x) âŠ† x. Es gilt: PRE(X) ist abgeschlossen unter PrÃ¤fixen.

Gegenseitiger Ausschluss mit Formeln der PrÃ¤dikatenlogik:  
âˆ€ y âˆˆ PRE(x) âˆ© A\* : 0 â‰¤ \#\_{Bel} y - \#\_{Fr} y â‰¤ 1

	#_{Bel} y - #_{Fr} y | Bedeutung
	â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“
	          0          |   frei
	          1          |  belegt

âˆ€ i âˆˆ N: Belâ±\_{x} â‰¤ Frâ±\_{x} â‰¤ Belâ±âºÂ¹\_{x}  
âˆ€ k, l âˆˆ N. fráµ\_{i x} \< belË¡\_{j x} âˆ¨ frË¡\_{j x} \< beláµ\_{i x}

![](Zustandsautomat.jpg)

#### Lineare Temporale Logik
Hier: Lineare Temporale **Aussagen**logik.  
Syntax: Formeln sind aufgebaut mit

- true, false
- Variablen
- VerknÃ¼pfungen âˆ§, âˆ¨, Â¬ (weitere VerknÃ¼pfungen kÃ¶nnen damit definiert werden, z.B. â‡’, â‡”, âŠ—. Endliche Quantoren
	![](Ablauf.jpg)
	mit M endlich.)
- temporale Operatoren
	-  âƒ
		- â€nextâ€œ
		- â€im nÃ¤chsten Zustand giltâ€œ
	-  âƒ
		- â€alwaysâ€œ
		- â€in allen zukÃ¼nftigen ZustÃ¤nden giltâ€œ
	-  âƒŸ
		- â€eventuallyâ€œ
		- â€in mindestens einem zukÃ¼nftigen Zustand giltâ€œ

Beispiel: â€Wer A sagt, muss auch B sagen.â€œâ€¨âƒ (A â‡’  âƒŸ B)

â€Never change a running system.â€œâ€¨âƒ (R â‡’  âƒ R)  
gleichwertig:  âƒ (R â‡’  âƒ R)

Semantik:

- ğœ sei ein serieller Ablauf
- j sei eine natÃ¼rliche Zahl
- p sein eine temporal-logische Formel

(ğœ, j) âŠ¨ p  
â€Formel p gilt an Position j des Ablaufs ğœ.â€œ  
Das wird rekursiv definiert durch:  
(ğœ, j) âŠ¨ p âˆ§ q : â‡” (ğœ, j) âŠ¨ q  
usw.

(ğœ, j) âŠ¨  âƒ p : â‡” (ğœ, j + 1) âŠ¨ p  
(ğœ, j) âŠ¨  âƒ p : â‡” âˆ€ k â‰¥ j: (ğœ, k) âŠ¨ p
(ğœ, j) âŠ¨  âƒŸ p : â‡” âˆƒ k â‰¥ j: (ğœ, k) âŠ¨ p

Gegenseitiger Ausschluss mit temporal-logischen Formeln:  
Beispiel:  
z\_{x} : â‡” 0 â‰¤ \#\_{Bel} x - \#\_{Fr} x â‰¤ 1  
 âƒ z

Kein Verhungern:  
beant\_{i x} : â‡” \#\_{antáµ¢} x \> \#\_{beláµ¢} x  
â€Thread i hat die Sperre beantragt, aber noch nicht belegt.â€œ

a\_{x} soll bedeuten:  
Aktion a ist im Zustand x soeben ausgefÃ¼hrt worden.
![](#)
Semantik dazu:  
(ğœ, j) âŠ¨ a : â‡” ğœ(j) = a

âƒ (beantáµ¢ â‡’  âƒŸ beláµ¢)

## 3. Synchronisation
### 3.1. Signale
**Synchronisation (hier)** := dafÃ¼r sorgen, dass gewisse AblÃ¤ufe ausgeschlossen sind.  
Auch: Koordination.  
**Signal (auch: Handshake, Meldung, engl. notification)** := Hinweis an einen anderen Thread, dass er weitermachen kann.

Analogie:

- Startschuss beim Wettlauf
- Staffel beim Staffellauf
- Anschlusszug mus warten
- Becher vor Kaffeezulauf

Ein Signal kann durch eine Sperre implementiert werden:

- signalisieren (auch: melden) = freigeben
- warten = belegen

Das Signal soll garantieren, dass eine gewisse Reihenfolge eingehalten wird.

pâ‚: Sâ‚;  
freigeben(l);

pâ‚‚: belegen(l);  
Sâ‚‚;

![](Reihenfolge.jpg)

l muss freigegeben worden sein, bevor es wieder belegt werden kann, also findet Sâ‚ vor Sâ‚‚ statt:

Durch die Verwendung von Signal wird schrÃ¤nkt man die Menge der AblÃ¤ufe ein. Nachteil: weniger ParallelitÃ¤t.  
Extremfall: Nur noch eine Reihenfolge mÃ¶glich, der Abauf wird seriell. Abgesehen vom Koordinationsaufwand zu einem seriellen Programm gleichwertig.

### 3.2. Beispiel: Erzeuger/Verbraucher-Problem, 1. Version
Erzeuger und Verbraucher sind Threads. Der Erzeuger erzeugt DatenblÃ¶cke. Der Verbraucher holt die DatenblÃ¶cke ab und verarbeitet sie.  
Die erzeugten aber noch nicht verbrauchten DatenblÃ¶cke werden in einem Puffer (:= Warteschlange) zwischengespeichert.

##### 1. Version:
1 Erzeuger  
1 Verbraucher  
Puffer fÃ¼r 1 Datenblock
	Thread erz:
		Wiederhole
			herstellen(datenblock);
			einreihen(puffer, datenblock);
	
	Thread verb:
		Wiederhole
			abholen(puffer, datenblock);
			verarbeiten(datenblock);

Prozedur `einreihen(puffer, datenblock)`:  
â‘  `belegen(leer);`  
â‘¡ `kopieren(datenblock; puffer);` (kopiert Datenblock in Puffer)  
â‘¢ `freigeben(voll);`

Prozedur `abholen(puffer, datenblock)`:  
â‘£ `belegen(voll);`  
â‘¤ `kopieren(puffer, datenblock);` (kopiert Puffer in Datenblock)  
â‘¥ `freigeben(leer);`

Hauptprogramm (HP):

	Sperre voll anlegen; // als belegt
	Sperre leer anlegen; // als belegt
	Threads erz und verb anlegen und laufen lassen;

â“ª `freigeben(leer);`

![](Kausalitaet.jpg)

â€”\> Programm-Reihenfolge  
--\> Reihenfolge erzwungen durch Signal

![](Petri-Netz.jpg)

![](Kausalitaetsgraph.jpg)![](Elementare%20Ereignisstruktur.jpg)

Ereignis eâ‚ *ist kausal fÃ¼r* Ereignis eâ‚‚: â‡”  
In jedem Ablauf gilt: Wenn eâ‚‚ stattfindet, dann hat eâ‚ vorher stattgefunden.  
Mit anderen Worten: eâ‚‚ kann erst stattfinden, wenn eâ‚ vorher stattgefunden hat.

![](Signaldiagramm.jpg)

Verwendung der Sperren voll und leer bewirkt hier:

1. â‘¡ und â‘¤ werden als kritische Bereiche behandelt.
2. â‘¡ und â‘¤ werden nur abwechselnd ausgefÃ¼hrt.

Zu 1.: Gegenseitiger Ausschluss gilt. Â¬leer.frei âˆ¨ Â¬voll.frei ist Invariante.  
Zu 2.: Folgt aus Programmreihenfolge und 1.

### 3.3. Semaphore
**Semaphor** := Datenstruktur l mit Zustand l.frei âˆˆ Nâ‚€ und Operationen â€belegenâ€œ und â€freigebenâ€œ.

Sperre ist Spezialfall mit l.frei âˆˆ {0, 1}.

belegen(l): Wendet bis l.frei \> 0 und setzt dann l.frei auf l.frei - 1.  
freigeben)l): Setzt l.frei auf l.frei + 1.

Zweck: l.frei verschiedene Kopien eines Betriebsmittels werden verwaltet.

Zusammenhang zu KlammerausdrÃ¼cken:

- â€(â€œ bedeutet â€freigeben(l)â€œ
- â€)â€œ bedeutet â€belegen(l)â€œ
- l.frei = Anzahl der noch offenen Klammern

![](Bikini.jpg)

### 3.4. Erzeuger/Verbraucher-Problem, 2. Version
2. Version: 1 Erzeuger, 1 Verbraucher, N DatenblÃ¶cke mit N \> 0 beliebig.

Threads erz und verb wie in Version 1.
	Prozedur einreihen(puffer, datenblock):
		belegen(nichtvoll); // *I' gilt*
		stock(puffer, datenblock);
		// â†‘ AnfÃ¼gen des Datenblocks am Puffer hinten
		freigeben(nichtleer); // *I gilt*

	Prozedur abholen(puffer, datenblock):
		belegen(nichtleer); // *I' gilt*
		datenblock := top(puffer);
		// â†‘ liefert vordersten Datenblock des Puffers
		pop(puffer);
		freigeben(nichtvoll); *I gilt*

Hauptprogramm:

- Leeren Puffer anlegen
- Semaphore nichtvoll und nichtleer erzeugen mit nichtvoll.frei = 0 und nichtleer.frei = 0.
- Threads erz und verb anlegen und laufen lassen.
		freigebená´º(nichtvoll);
		// nichtvoll wird N-mal freigegeben, *I gilt*

Invariante *I*: 0 â‰¤ nichtvoll.frei â‰¤ N âˆ§ nichtleer.frei + nichtvoll.frei â‰¤ *N*  
Invariante *I'*: 0 â‰¤ nichtvoll.frei â‰¤ N âˆ§ nichtleer.frei + nichtvoll.frei â‰¤ *N - 1*  
Invariante *I"*: 0 â‰¤ nichtvoll.frei â‰¤ N âˆ§ nichtleer.frei + nichtvoll.frei â‰¤ *N - 2*

*I" gilt, wenn beide Threads belegen aufgerufen haben, aber noch nicht freigeben aufgerufen haben.*

### 3.5. Bedingte Kritische Bereiche
Ein kritischer Bereich soll nur betreten werden, wenn eine gewisse Bedingung B an die gemeinsame Variable gilt. Wie implementiert man das?

1. B vor dem Betreten des kritischen Bereiches Ã¼berprÃ¼fen.  
	Problem: B kann beim Betreten des kritischen Bereiches bereits wieder verletzt sein.
2. B im kritischen Bereich Ã¼berprÃ¼fen.  
	Problem: Solange B nicht gilt, soll der Thread warten.  
	Weil er sich im kritischen Bereich befindet, kÃ¶nnen andere Threads die gemeinsame Variable nicht Ã¤ndern, und damit den Wert von B.

Mit kritischen Bereichen kann man das Problem nicht lÃ¶sen.  
Abhilfe: neues Konstrukt.

Warteanweisung:

	warte auf B;

B := Bedingung an gemeinsame Variable (bewacht von Sperre l)

Beispiel-Implementierung:

	Solange Â¬B wiederhole
		freigeben(l);
		belegen(l);

Warteanweisung steht im kritischen Bereich:

	kritisch l {
		â‹®
		warte auf B;
		â‹®
	}

Implementierung bedingter kritischer Bereiche in Java: â€Bedingungsvariableâ€œ

Typ Condition  
Bedingungsvariable wird einer Sperre zugeordnet.  
Z.B.

	Lock l = new ReentrantLock();
	Condition c = new Condition(l); // <- Bedingte Variable c ist der Sperre l zugeordnet

Werteanweisung: `wait(c);`  
Signalisieren: `signal(c);` oder `signalAll(c);`  
Empfohlen ist `signalAll(c)`  
Warteanweisung soll implementiert werde durch:

	while (Â¬B) { // Bedingte Variable c â€vertrittâ€œ die Bedingung B.
		wait(c); // Signal an c bedeutet:
	}            // â€Bedingung B kÃ¶nnte erfÃ¼llt seinâ€œ

Keine Garantie!

### 3.6. Erzeuger/Verbraucher-Problem, 3. Version
Beliebig viele Erzeuger, beliebig viele Verbraucher, Puffer mit N DatenblÃ¶cken.

	einreihen(puffer, datenblock):
		kritisch l {
			warte auf lÃ¤nge(puffer) < N;
			stock(puffer, datenblock);
		}
	
	abholen(puffer, datenblock):
		kritisch l {
			warte auf lÃ¤nge(puffer) > 0;
			datenblock := top(puffer);
			pop(puffer);
		}
	
	// lÃ¤nge(puffer) liefert die Anzahl der DatenblÃ¶cke,
	// die sich gerade im Puffer befinden
	
	Hauptprogramm:
		Erzeugen des Puffers; Puffer ist leer.
		Erzeugen der Sperre l fÃ¼r den Puffer.
		Erzeugen der Threads und Starten der Threads.

	// Version mit Bedingungsvariablen:
	einreihen(puffer, datenblock):
		belegen(l);
		solange lÃ¤nge(puffer) < N wiederhole:
			wait(nichtvoll);
		stock(puffer, datenblock);
		signalAll(nichtleer);
		falls lÃ¤nge(puffer) < N, dann:
			signalAll(nichtvoll);
		freigeben(l);
	
	abholen(puffer, datenblock):
		belegen(l);
		solange lÃ¤nge(puffer) > 0 wiederhole:
			wait(nichtleer);
		datenblock := top(puffer);
		pop(puffer);
		signalAll(nichtvoll);
		falls lÃ¤nge(puffer) > 0, dann:
			signalAll(nichtleer);
		freigeben(l);

## Seminare
### Aufgabe 1:
Es soll ein Java-Hauptprogramm geschrieben werden, in dem 8 Threads angelegt werden. Jeder Thread *i* soll auf dem Bildschirm ausgeben â€Hello World from Thread *i*â€œ.

##### Muster:
	import java.lang.threads.*;
	
	public static void main() {
		Thread[] threads = new Thread[8];
		for (int i = 0; i < 8; i++) {
			final int c = i;
			thread[i] = new Thread(
				new Runnable() {
					public void run() {
						System.out.println(
							"Hello World from Thread " + c
						);
					}
				}
			);
		}
		for (int i = 0; i < 8; i++) {
			thread[i].start();
		}
		for (int i = 0; i < 8; i++) {
			thread[i].join();
		}
	}

### Aufgabe 2:
1. Es soll ein Java-Hauptprogramm geschrieben werden, in dem eine globale Variable *z* auf 0 initialisiert wird und von jedem der 10000 Threads inkrementiert wird. Interpretieren Sie das Ergebnis.
2. Ersetzen Sie z++ durch den Aufruf einer Methode.

##### Muster 1:
	import java.lang.threads.*;
	
	static int z = 0;
	
	public static void main() {
		Thread[] threads = new Thread[8];
		for (int i = 0; i < 10000; i++) {
			final int c = i;
			thread[i] = new Thread(
				new Runnable() {
					public void run() {
						z++;
					}
				}
			);
		}
		for (int i = 0; i < 10000; i++) {
			thread[i].start();
		}
		for (int i = 0; i < 10000; i++) {
			thread[i].join();
		}
	}

##### Muster 2:
	import java.lang.threads.*;
	
	static int z = 0;
	
	public static void main() {
		Thread[] threads = new Thread[8];
		for (int i = 0; i < 10000; i++) {
			final int c = i;
			thread[i] = new Thread(
				new Runnable() {
					public void run() {
						inc();
					}
				}
			);
		}
		for (int i = 0; i < 10000; i++) {
			thread[i].start();
		}
		for (int i = 0; i < 10000; i++) {
			thread[i].join();
		}
	}
	synchronized static void inc() {
		z++;
	}

### Aufgabe: Amdahls Gesetz
1. Finden Sie heraus, welcher Anteil der ZÃ¤hler-Aufgabe (mit k = 10000 Threads) parallelisierbar ist.
2. Welchen Anteil erwarten Sie fÃ¼r k = 20000 Threads?
3. Wie weit kann man die Bearbeitung durch Parallelisierung beschleunigen, wenn man beliebig viele Prozessoren zur VerfÃ¼gung hat?

##### LÃ¶sung:
Parallelisierter Anteil: `p = ((b / a - 1) * n) / (1 - n)`  
a: serielle Bearbeitungszeit; b: parallele Bearbeitungszeit

Beschleunigung: `1 / (1 - p)`.

### Aufgabe: VerschrÃ¤nkung (1)
Thread p habe m Schritte, Thread q habe n Schritte auszufÃ¼hren.

1. Geben Sie eine rekursive Definition an fÃ¼r die Anzahl anz(m, n) der mÃ¶glichen verschrÃ¤nkten AblÃ¤ufe von p und q.
2. Finden Sie einen geschlossenen Ausdruck fÃ¼r anz(m, n).
3. SchÃ¤tzen Sie die GrÃ¶ÃŸenordnung von anz(n, n).

##### LÃ¶sung:
1. Formel:
		anz(m, n) = { 1, falls m = 0 oder n = 0
		            { anz(m - 1, n) + anz(m, n - 1), sonst
2. Wegbeschreibung = Bitvektor mit m Nullen und n Einsen  
	(0 â‰™ 1 Schritt nach rechts, 1 â‰™ 1 Schritt nach unten)
	LÃ¤nge des Bitvektors ist m + n.
	Isomorph zu Bitvektor mit m Nullen und n Einsen sind n-Teilmengen einer (m+n)-Menge.
	Beispiel: Bitvektor `011010`
	(m+n)-Menge sei `{1, â€¦, m + n}`.
	Dargestellte Teilmenge ist `{2, 3, 5}`.
	Satz: Die Anzahl der k-Teilmengen einer n-Menge ist *n Ã¼ber k* (Binomialkoeffizient).
	Es gilt `anz(m, n)` = `(m + n)` *Ã¼ber* `n`.
3. Behauptung: `anz(n, n)` = `2n` *Ã¼ber* `n` â‰¥ 2â¿ - 1 fÃ¼r n â‰¥ 1.
	Beweis:
	1. n = 1: `anz(n, n)` = `2` *Ã¼ber* `1` = 2
	2. n \> 1: `anz(n, n)` = `2n` *Ã¼ber* `n` = `2n - 1` *Ã¼ber* `n` + `2n - 1` *Ã¼ber* `n - 1` â‰¥  
		`2â¿` = `2 * 2â¿â»Â¹` â‰¤ `2 * 2 (n - 1)` *Ã¼ber* `n - 1` â‰¤  
		weil `2n - 1` *Ã¼ber* `n - 1` â‰¥ `2n - 2` *Ã¼ber* `n - 1` und `2n - 1` *Ã¼ber* `n` â‰¥ `2n - 2` *Ã¼ber* `n - 1`  
		`2n - 1` *Ã¼ber* `n - 1` = `2n - 2` *Ã¼ber* `n - 1` + `2n - 2` *Ã¼ber* `n - 2`

### Umgang mit Sperren in Java:
	package.â€¦;
	import java.util.concurrent.locks.*;
	â€¦
	private static Lock lock;
	â€¦
	lock = new ReentrantLock();
	â€¦
	lock.lock();
	try {
		â€¦ // kritischer Bereich
	}
	finally {
		lock.unlock();
	}

`lock.unlock` wird immer abschlieÃŸend ausgefÃ¼hrt, auch wenn der try-Block eine Ausnahme auslÃ¶st.

### Aufgabe: VerschrÃ¤nkung (2)
n Threads sollen verschrÃ¤nkt zueinander laufen. Jeder Thread habe 2 Schritte auszufÃ¼hren.

1. Geben Sie eine rekursive Definition an fÃ¼r die Anzahl anz\*(n) der mÃ¶glichen AblÃ¤ufe.
2. Finden Sie einen geschlossenen Ausdruck fÃ¼r anz\*(n).
3. SchÃ¤tzen Sie die GrÃ¶ÃŸenordnung von anz\*(n).

##### LÃ¶sung:
1. Es gilt anz\*(1) = 1. Sei nun n \> 1. Nach IV liefert anz\*(n - 1) die Anzahl der mÃ¶glichen AblÃ¤ufe fÃ¼r n - 1 Threads.
	![](Schrittverteilung.jpg)
	Also gilt:

		anz*(n) = {1, falls n = 1,
		          {anz*(n-1) * (2n-1) * (n-1), sonst.

### Aufgabe: Zeitliche AblÃ¤ufe
1. Geben Sie zu folgendem zeitlichen Ablauf den passenden seriellen Ablauf (Aktionenfolge) an:  
	{(a, 5.3), (b, 3.7), (c, 3.2), (a, 1.7), (a, 2.1), (b, 2.5)}.
	##### LÃ¶sung:
	{(a, 1.7), (a, 2.1), (b, 2.5), (c, 3.2), (b, 3.7), (a, 5.3)}

		f(x) = { a, falls x âˆˆ {1, 2, 6}
		       { b, falls x âˆˆ {3, 5}
		       { c, sonst

2. Welche der folgenden Mengen von Ereignissen sind diskrete zeitliche AblÃ¤ufe? Dazu sei A = {a, b}.  
	âº) {(a, -3), (a, 25), (b, 2)} **âœ“**  
	Î²) {a} â¨‰ N **âœ“**  
	É£) {a} â¨‰ Zâ»**âœ—** (kein kleinstes Element)  
	Æ) {(a, 1 + (1/i) | i âˆˆ N} âˆª {(a, 0)} **âœ—** (HÃ¤ufung bei t = 1  
	Îµ) {(a, 1 + (1/i) | i âˆˆ N, i \< 100} **âœ“**  
	Î¶) {a, 3), (b, 5), (b, 3)} **âœ—** (verschiedene gleichzeitige Ereignisse)
3. Geben Sie zu jedem diskreten zeitlichen Ablauf aus Teilaufgabe 2 die Ereignisse EÂ¹, EÂ², EÂ³ an.  
	âº: EÂ¹ = (a, - 3), EÂ² = (b, 2), EÂ³ = (a, 25).  
	Î²: EÂ¹ = (a, 1), EÂ² = (a, 2), EÂ³ = (a, 3).  
	Îµ: EÂ¹ = (a, 1 + (1/99)), EÂ² = (a, 1 + (1/98)), EÂ³ = (a, 1 + (1/97)).

### Aufgabe: Einigkeit
Beweisen Sie, dass fÃ¼r alle Threads pâ‚, pâ‚‚ folgende Aussagen Ã¤quivalent sind:  
âº) Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âˆª Eâ‚‚) = Eâ‚ âˆ© Eâ‚‚  
Î²) Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âŠ• Eâ‚‚) = Ã˜  
É£) Ï€\_{Aâ‚}(Eâ‚‚) = Ï€\_{Aâ‚‚}(Eâ‚)

Dabei sei Aáµ¢ das Prozessalphabet von Thread páµ¢ und Eáµ¢ der zeitliche Ablauf von Thread páµ¢, i âˆˆ {1, 2}.  
Dann gilt: Ï€\_{Aáµ¢}(Eáµ¢) = Eáµ¢

##### LÃ¶sung
###### Zu zeigen: Î² âŸ¹ âº
Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âˆª Eâ‚‚) = Ï€\_{Aâ‚ âˆ© Aâ‚‚}((Eâ‚ âŠ• Eâ‚‚) âˆª (Eâ‚ âˆ© Eâ‚‚))  
= Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âŠ• Eâ‚‚) âˆª Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âˆ© Eâ‚‚)  
= Ã˜ âˆª Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âˆ© Eâ‚‚)  
= Ï€\_{Aâ‚}(Ï€\_{Aâ‚‚}(Eâ‚ âˆ© Eâ‚‚))  
= Ï€\_{Aâ‚}(Ï€\_{Aâ‚‚}(Eâ‚) âˆ© Ï€\_{Aâ‚‚}(Eâ‚‚))

###### Zu zeigen: âº âŸ¹ Î²
Ï€\_{Aâ‚}(Eâ‚ âŠ• Eâ‚‚) = Ï€\_{Aâ‚ âˆ© Aâ‚‚}((Eâ‚ âˆª Eâ‚‚)\\(Eâ‚ âˆ© Eâ‚‚))  
= Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âˆª Eâ‚‚)\\Ï€\_{Aâ‚ âˆ© Aâ‚‚(Eâ‚ âˆ© Eâ‚‚)  
= (Eâ‚ âˆ© Eâ‚‚)\\(Eâ‚ âˆ© Eâ‚‚) = Ã˜

###### Zu zeigen: Î² âŸ¹ É£
Ï€\_{Aâ‚}(Eâ‚) = Ï€\_{Aâ‚‚}(Eâ‚‚)  
**(1)** Ï€\_{Aâ‚}(Eâ‚‚)\\Ï€\_{Aâ‚‚}(Eâ‚) = Ã˜ âŸº Ï€\_{Aâ‚}(Eâ‚‚) â‰¤ Ï€\_{Aâ‚‚}(Eâ‚)  
**(2)** Ï€\_{Aâ‚‚}(Eâ‚)\\Ï€\_{Aâ‚}(Eâ‚‚) = Ã˜ âŸº Ï€\_{Aâ‚‚}(Eâ‚) â‰¤ Ï€\_{Aâ‚}(Eâ‚‚)

**(1)** âˆ© **(2)**  
âŸº Ï€\_{Aâ‚}(Eâ‚‚)\\Ï€\_{Aâ‚‚}(Eâ‚) âˆª Ï€\_{Aâ‚‚}(Eâ‚)\\Ï€\_{Aâ‚}(Eâ‚‚) = Ã˜  
âŸº Ï€\_{Aâ‚}(Eâ‚‚) âŠ• Ï€\_{Aâ‚‚}(Eâ‚) = Ã˜

Noch zu zeigen: Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âŠ• Eâ‚‚) = Ï€\_{Aâ‚}(Eâ‚‚) âŠ• Ï€\_{Aâ‚‚}(Eâ‚)  
Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âŠ• Eâ‚‚) = Ï€\_{Aâ‚}(Ï€\_{Aâ‚‚}(Eâ‚ âŠ• Eâ‚‚))  
= Ï€\_{Aâ‚}(Ï€\_{Aâ‚‚}(Eâ‚) âŠ• Ï€\_{Aâ‚‚}(Eâ‚‚))  
= Ï€\_{Aâ‚}(Ï€\_{Aâ‚‚}(Eâ‚) âŠ• Eâ‚‚)
= Ï€\_{Aâ‚}(Ï€\_{Aâ‚‚}(Eâ‚)) âŠ• Ï€\_{Aâ‚}(Eâ‚‚)  
= Ï€\_{Aâ‚‚}(Ï€\_{Aâ‚}(Eâ‚)) âŠ• Ï€\_{Aâ‚}(Eâ‚‚)  
= Ï€\_{Aâ‚‚}(Eâ‚) âŠ• Ï€\_{Aâ‚}(Eâ‚‚)

###### Zu zeigen: É£ âŸ¹ Î²
Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âŠ• Eâ‚‚)  
= Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚) âŠ• Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚‚)  
= Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚)\\Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚‚) âˆª Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚‚)\\Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚) = Ã˜

Zu zeigen dazu:  
Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚) = Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚‚)  
Ï€\_{Aâ‚‚}(Ï€\_{Aâ‚}(Eâ‚) = Ï€\_{Aâ‚}(Ï€\_{Aâ‚‚}(Eâ‚‚)  
Eâ‚ = Eâ‚‚

###### Anderer Weg fÃ¼r É£ âŸ¹ Î²
Ï€\_{Aâ‚ âˆ© Aâ‚‚}(Eâ‚ âŠ• Eâ‚‚) = Ï€\_{Aâ‚}(Ï€\_{Aâ‚‚}(Eâ‚ âŠ• Eâ‚‚))  
= Ï€\_{Aâ‚}(Ï€\_{Aâ‚‚}(Eâ‚) âŠ• Ï€\_{Aâ‚‚}(Eâ‚‚))  
= Ï€\_{Aâ‚}(Ï€\_{Aâ‚}(Eâ‚‚) âŠ• Eâ‚‚)  
= Ï€\_{Aâ‚}(Eâ‚‚) âŠ• Ï€\_{Aâ‚}(Eâ‚‚) = Ã˜

### Aufgabe:
1. Beweisen Sie, dass â€â†’â€œ eine Wohlordnung (das heiÃŸt irreflexiv, transitiv, total, fundiert) ist.
	##### LÃ¶sung
	- irreflexiv: Beweis durch Widerspruch.  
		Annahme: e â†’ e gilt.  
		Nach Definition von â€â†’â€œ gilt zeit(e) \< zeit(e).  
		Widerspruch zu \< irreflexiv.
	- transitiv: a â†’ b & b â†’ c & a â†’ c  
		zeit(a) \< zeit(b)  
		zeit(b) \< zeit(c) âŸ¹ zeit(a) \< zeit(c)
	- total: zu zeigen fÃ¼r Ereignisse eâ‚ â‰  eâ‚‚ gilt eâ‚ â†’ eâ‚‚ oder eâ‚‚ â†’ eâ‚.  
		Seien eâ‚ â‰  eâ‚‚ Ereignisse. Dann  
		zeit(eâ‚) \< zeit(eâ‚‚) oder  
		zeit(eâ‚‚) \< zeit(eâ‚) oder  
		zeit(eâ‚) = zeit(eâ‚‚)  
		weil \< total.  
		Wenn zeit(eâ‚) = zeit(eâ‚‚), dann eâ‚ = eâ‚‚ nach Vorraussetzung (idealisierende Annahme 3). Widerspruch zu eâ‚ â‰  eâ‚‚.  
		Also entweder zeit(eâ‚) \< zeit(eâ‚‚).  
		Damit eâ‚ â†’ eâ‚‚.  
		Oder es gibt zeit(eâ‚‚) \< zeit(eâ‚).  
		Damit eâ‚‚ â†’ eâ‚.
	- fundiert: Zu zeigen: Es gibt keine unendliche â†-Kette. (â†’ umgekehrt)  
		Beweis durch Widerspruch.  
		Annahme: (eáµ¢)\_{i âˆˆ N} sei unendliche â†-Kette.  
		Damit: eáµ¢ â† eáµ¢â‚Šâ‚ fÃ¼r alle i âˆˆ N.  
		Damit zeit(eáµ¢) \> zeit(eáµ¢â‚Šâ‚) fÃ¼r alle i âˆˆ N wegen Definition von â†’.  
		Damit ist (zeit(eáµ¢))\_{i âˆˆ N} eine unendliche \>-Kette.  
		Widerspruch zu: \< ist fundiert auf N.
2. Welche der Eigenschaften irreflexiv, transitiv, total, fundiert gelten auch fÃ¼r â†’ auf ZeitrÃ¤umen? 
	##### LÃ¶sung
	- irreflexiv: A â†’ A gilt nicht, denn Ende von A kommt immer *nach* Anfang von A. Deswegen â†’ irreflexiv.
	- transitiv: Sei A â†’ B und B â†’ C.  
		anfang(A), ende(A)  
		Wenn A Zeitraum, dann anfang(A) â†’ ende(A).  
		A â†’ B âŸº ende(A) â†’ anfang(B)  
		B â†’ C âŸº ende(B) â†’ anfang(C)  
		Damit ende(A) â†’ anfang(B) â†’ ende(B) â†’ anfang(C).  
		Weil â†’ transitiv (auf Ereignissen), deswegen ende(A) â†’ anfang(C), also A â†’ C. Also â†’ transitiv (auf ZeitrÃ¤umen).
	- total: Nein, denn ZeitrÃ¤ume kÃ¶nnen sich Ã¼berlappen.
	- fundiert: Behauptung: â†’ fundiert auf ZeitrÃ¤umen.  
		Beweis durch Widerspruch.  
		Annahme: (Aáµ¢)\_{i âˆˆ N} unendliche â†-Kette.  
		Dann gilt fÃ¼r alle i âˆˆ N: Aáµ¢ â† Aáµ¢â‚Šâ‚, das heiÃŸt ende(Aáµ¢â‚Šâ‚) â†’ anfang(Aáµ¢).  
		Dann anfang(Aáµ¢) â† ende(Aáµ¢â‚Šâ‚) â† anfang(Aáµ¢â‚Šâ‚) (Aáµ¢â‚Šâ‚ ist ein Zeitraum).  
		Dann anfang(Aáµ¢) â† anfang(Aáµ¢â‚Šâ‚) wegen â†’ transitiv.  
		Also (anfang(Aáµ¢))\_{i âˆˆ N} unendliche â†-Kette (auf Ereignissen).  
		Widerspruch zu â†’ fundiert (auf Ereignissen).

## Einschub: Threads in Haskell
Haskell ist eine *funktionale Programmiersprache*, das heiÃŸt eigentlich: Haskell unterstÃ¼tzt besonder den funktionalen Programmierstil.

##### Funktionaler Programmierstil:
- AusdrÃ¼cke
- rekursive Funktionsdefinitionen

###### ZusÃ¤tzlich:
- starkes Typsystem

##### Gegensatz: imperativer Stil
- Anweisungen
- Schleifen

### Glasgow Haskell Compiler (GHC)
Bibliothek: `Control.Concurrent`  
`forkIO p` (Funktionsaufruf mit Funktion `forkIO` und Parameterausdruck `p`) erzeugt einen Thread, in dem das Programm `p` lÃ¤uft. (:: â‰™ â€hat den Typâ€œ)

	forkIO :: IO() -> IOThreadId

Typ einer Synchronisationsvariablen, die Werte vom Typ `t` enthÃ¤lt:

	MVar t

v vom Typ `MVar t` kann nie leer sein oder einen Wert (vom Typ `t`) enthalten.

	putMVar :: MVar t â†’ t â†’ IO()
	putMVar v a

Warten bis v leer ist. Dann v mit Wert a auffÃ¼llen.

	takeMVar :: MVar t â†’ IO t
	takeMVar v

Warten bis v voll ist. Dann den Wert von v entnehmen.

##### Beispiel: Hello-World mit Threads in Haskell:
	import Control.Concurrent
	hello i l = do
		takeMVar l
		putStrLn("Hallo von " ++ show i)
		putMVar l ()
	
	main = do
		l <- newEmptyMVar
		forkIO (hello 1 l) } forM_ [1..4] (\k ->
		forkIO (hello 2 l) } forkIO (hello k l))
		forkIO (hello 3 l) } (definiert in
		forkIO (hello 4 l) } Control.Monad)

##### Î»-Abstraktion:
	forM_ [1..4] (\k -> forkIO (hello k l))

Definition einer anonymen Funktion (Funktion ohne Namen)

	import Control.Concurrent
	import Control.Monad
	import Data.IORef
	
	inc z = do
		v <- readIORef z
		writeIORef z (v + 1)
	
	main = do
		z <- newIORef 0
		forM_ [1..10000]
			(\k -> forkIO (inc z))

### Aufgabe:
1. Welche Eigenschaft eines Systems von Threads wird ausgedrÃ¼ckt mit der Formel:  
	Ï€\_{s}(x) âˆˆ PRE((antáµ¢ beláµ¢ fráµ¢)^{âˆ})  
	wobei s := {antáµ¢ beláµ¢ fráµ¢}.
2. Handelt es sich dabei um eine Sicherheitseigenschaft oder eine Liveness-Eigenschaft?
3. ErfÃ¼llt der Ablauf x = antáµ¢ beláµ¢ die Formel?
4. Geben Sie einen Beispiel-Ablauf mit 2 Threads an, der die Formel fÃ¼r i = 1 und fÃ¼r i = 2 erfÃ¼llt, aber gegenseitigen Auschluss verletzt.

##### LÃ¶sung
1. Programm-Reihenfolge fÃ¼r Thread i.
2. Sicherheitseigenschaft
3. Ja, weil antáµ¢ beláµ¢ â‰¤\_{pre} (antáµ¢ beláµ¢ fráµ¢)^{âˆ}.
4. Beispiel: x = antâ‚ belâ‚ antâ‚‚ belâ‚‚ (eine Faire Mischung von antâ‚ belâ‚ und antâ‚‚ belâ‚‚).

Frage: ErfÃ¼llt belâ‚„ antâ‚… die Formel?

FÃ¼r i = 4:  
Ï€\_{s}(x) = belâ‚„ âˆ‰ PRE((antâ‚„ belâ‚„ frâ‚„)^{âˆ})  
Formel ist nicht erfÃ¼llt.

FÃ¼r i = 5:
Ï€\_{s}(x) = antâ‚… âˆ‰ PRE((antâ‚… belâ‚… frâ‚…)^{âˆ})  
Formel ist erfÃ¼llt.

FÃ¼r alle i âˆ‰ {4, 5} gilt:  
Ï€\_{s}(x) = Îµ âˆˆ PRE((antáµ¢ beláµ¢ fráµ¢)^{âˆ})  
Formel ist erfÃ¼llt.

### Aufgabe:
Beweisen Sie, dass fÃ¼r alle x âˆˆ A^{âˆ}  
(1) 0 â‰¤ \#\_{Bel}y - \#\_{Fr}y â‰¤ 1 fÃ¼r alle y â‰¤\_{pre}x mit y âˆˆ A\*  
Ã¤quivalent ist zu  
(2) âˆ€ i âˆˆ N: Belâ±\_{x} â‰¤ Frâ±\_{x} â‰¤ Belâ±âºÂ¹\_{x}
##### LÃ¶sung:

(1) â‡’ (2):  
Sei i âˆˆ N beliebig. Beweis mit Widerspruch. Annahme: Frâ±\_{x} \< Belâ±\_{x}.

	â›#_{Fr}y < iâ â›#_{Fr}y â‰¥ i, #_{Bel}y < iâ  Damit gilt (1) nicht.
	â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“
	          Frâ±_{x}                     Belâ±_{x}

Widerspruch!

Annahme: Belâ±âºÂ¹\_{x} \< Frâ±\_{x}.

	        â›#_{Bel}< â‰¥ i + 1, #_{Fr} y < iâ
	â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“
	   Belâ±âºÂ¹_{x}                        Frâ±_{x}

Damit gilt (1) nicht, Widerspruch!

(2) â‡’ (1):

	     â›#_{Bel}y â‰¥ i, â
	     |damit #_{Bel}y|
	     |- #_{Fr}y â‰¥ 1,| â›  #_{Fr}y â‰¥ i,  â
	     |es gilt sogar | |#_{Bel}y â‰¤ i + 1|
	     |  #_{Bel}y -  | |   #_{Bel}y -   |
	     | #_{Fr}y = 1. | |  #_{Fr}y â‰¤ 0   |
	â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“
	Belâ±_{x}         Frâ±_{x}           Belâ±âºÂ¹_{x}
	â______________________________________â 
	             #_{Bel}y â‰¤ i + 1
	                â›   â‘    ââ›   â‘¡   â
	â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“
	 Frâ±â»Â¹_{x}  Belâ±_{x}  Frâ±_{x}  Brâ±âºÂ¹_{x}  Frâ±âºÂ¹_{x}
	â(2) fÃ¼r i - 1â  â    (2) fÃ¼r i    â  â(2) fÃ¼r i + 1â 

FÃ¼r ZustÃ¤nde im Bereich â‘  gilt:
	#_{Bel}y â‰¥ i       } â‡’
	#_{Bel}y < i + 1   } #_{Bel} y â‰¥ i
	#_{Fr}y < i        } â‡’
	#_{Fr}y â‰¥ i - 1    } #_{Fr}y = i - 1

Damit \#\_{Bel}y - \#\_{Fr}y = 1; das erfÃ¼llt (1).

Frage: Gilt (1) auch fÃ¼r y im Bereich â“ª?

	â›  â“ª  â â›    â“ª'   â
	âŠ¢â€“â€“â€“â€“â€“â€“+â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“+â€“â€“â€“
	    BelÂ¹_{x}      FrÂ¹_{x}

Zu Temporaler Logik:  
Was bedeuten folgende Formeln?

1.  âƒp: p gilt ab jetzt immer
2.  âƒ âƒŸp: p gilt unendlich oft; p gilt immer wieder
3.  âƒŸ âƒp: ab einer gewissen Stelle gilt p immer; P gilt fast immer (:= immer bis auf endlich viele Ausnahmen)

Gesetze der Linearen Temporalen Logik:

1.  âƒp â‡’ p (Wenn p immer gilt, dann gilt p jetzt)
2.  âƒ(Â¬p) â‡” Â¬ âƒp
3.  âƒ(p â‡’ q) â‹€  âƒp â‡’  âƒq
4. p â‹€  âƒ(p â‡’  âƒp) â‡’  âƒp

[^1]:	Endliche Folgen

[^2]:	Unendliche Folgen

[^3]:	Leere Aktionenfolge (= Aktionenfolge der LÃ¤nge 0)

[^4]:	yâ‚€ \<\_{pre} x  
	Ï€\_{B}(yâ‚€) = Îµ

[^5]:	yâ‚ \<\_{pre} x  
	Ï€\_{B}(yâ‚) = (a)

[^6]:	Ï€\_{B}(yâ‚‚) = (a, b)

[^7]:	Ï€\_{B}(yâ‚ƒ) = (a, b)

[^8]:	Ï€\_{B}(yâ‚„) = (a, b, a)

[^9]:	â€PrÃ¤fix-Abschlussâ€œ